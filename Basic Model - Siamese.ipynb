{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IaNq2nbitoeC",
    "outputId": "67764ded-3c72-481d-bb01-c67f498a2be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "DK-o0nq7t8ra"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Bidirectional, Lambda, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Concatenate, Add, Subtract, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "WoXF3y1UuC7n"
   },
   "outputs": [],
   "source": [
    "q1_train_final = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/q1_train_final.npy\", allow_pickle='True')\n",
    "q2_train_final = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/q2_train_final.npy\", allow_pickle='True')\n",
    "q1_valid_final = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/q1_valid_final.npy\", allow_pickle='True')\n",
    "q2_valid_final = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/q2_valid_final.npy\", allow_pickle='True')\n",
    "y_train_final = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/y_train_final.npy\", allow_pickle='True')\n",
    "y_valid_final = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/y_valid_final.npy\", allow_pickle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "gGUgXqDO-kTl"
   },
   "outputs": [],
   "source": [
    "q1_test_padded = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/q1_test_padded.npy\", allow_pickle='True')\n",
    "q2_test_padded = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/q2_test_padded.npy\", allow_pickle='True')\n",
    "y_test = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/y_test.npy\", allow_pickle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "3w3peGwmvrFC"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(\"/content/drive/My Drive/Text Mining Project/Train_Valid_Split/embedding_matrix.npy\", allow_pickle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "P74H7zG9_glS"
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "2cCD9oofwxe0"
   },
   "outputs": [],
   "source": [
    "def manhattan_dist(q1_lstm_feature, q2_lstm_feature):\n",
    "  subtracted = Subtract()([q1_lstm_feature, q2_lstm_feature])\n",
    "  abs_diff = kb.abs(subtracted)\n",
    "  dist_score = kb.sum(abs_diff, axis=1, keepdims=True)\n",
    "  return dist_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "1HL2-8EWwyDb"
   },
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "q1_input = Input(shape=(60,), dtype='int32')\n",
    "q2_input = Input(shape=(60,), dtype='int32')\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(input_dim=len(embedding_matrix), output_dim=300, weights=[embedding_matrix], input_length=60, trainable=False)\n",
    "\n",
    "# The above Embedding layer is shared for both question1 and question2\n",
    "q1_embed = embedding_layer(q1_input)\n",
    "q2_embed = embedding_layer(q2_input)\n",
    "\n",
    "# lSTM layer\n",
    "lstm_layer = LSTM(units=50)\n",
    "\n",
    "# The above LSTM layer is shared for both question1 and question2\n",
    "q1_lstm = lstm_layer(q1_embed)\n",
    "q2_lstm = lstm_layer(q2_embed)\n",
    "\n",
    "'''\n",
    "We want to find manhattan distance between question1 feature and \n",
    "question2 feature from final hidden state of LSTM keeping the dimensions same \n",
    "'''\n",
    "dist_score = manhattan_dist(q1_lstm, q2_lstm)\n",
    "\n",
    "\n",
    "# Detect whether given set of questions are duplicate or not\n",
    "is_duplicate = Dense(1, activation=\"sigmoid\")(dist_score)\n",
    "\n",
    "# Combine into the Model\n",
    "model = Model(inputs=[q1_input, q2_input], outputs=is_duplicate)\n",
    "\n",
    "# Compiling the model\n",
    "'''\n",
    "Configurations:\n",
    "              Loss function used: Binary Cross Entropy\n",
    "              Optimizer: Nadam\n",
    "              metrics used: Accuracy\n",
    "'''\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "Callbacks:\n",
    "          EarlyStopping to avoid Overfitting\n",
    "          ModelCheckpoint to save best model in all epochs\n",
    "          TensorBoard Visulaization for Loss\n",
    "\n",
    "'''\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath='/content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                    monitor='val_loss', mode='min', save_best_only=True, verbose=1),\n",
    "    TensorBoard(log_dir='/content/drive/My Drive/Text Mining Project/Saved Model/Tensorboard/runs/'),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzcXIZG40GEH",
    "outputId": "13ec573a-4b6e-4df5-8afe-f14825ddcb6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "   1/5536 [..............................] - ETA: 0s - loss: 0.6961 - accuracy: 0.3125WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/5536 [..............................] - ETA: 21:48 - loss: 0.6887 - accuracy: 0.3359WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1249s vs `on_train_batch_end` time: 0.3475s). Check your callbacks.\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.7420\n",
      "Epoch 00001: val_loss improved from inf to 0.49655, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.01-0.50.h5\n",
      "5536/5536 [==============================] - 672s 121ms/step - loss: 0.5520 - accuracy: 0.7420 - val_loss: 0.4966 - val_accuracy: 0.7739\n",
      "Epoch 2/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.7878\n",
      "Epoch 00002: val_loss improved from 0.49655 to 0.46777, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.02-0.47.h5\n",
      "5536/5536 [==============================] - 672s 121ms/step - loss: 0.4742 - accuracy: 0.7878 - val_loss: 0.4678 - val_accuracy: 0.7868\n",
      "Epoch 3/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.8061\n",
      "Epoch 00003: val_loss improved from 0.46777 to 0.44745, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.03-0.45.h5\n",
      "5536/5536 [==============================] - 675s 122ms/step - loss: 0.4460 - accuracy: 0.8061 - val_loss: 0.4475 - val_accuracy: 0.8038\n",
      "Epoch 4/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8176\n",
      "Epoch 00004: val_loss improved from 0.44745 to 0.43903, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.04-0.44.h5\n",
      "5536/5536 [==============================] - 677s 122ms/step - loss: 0.4294 - accuracy: 0.8176 - val_loss: 0.4390 - val_accuracy: 0.8128\n",
      "Epoch 5/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.8250\n",
      "Epoch 00005: val_loss improved from 0.43903 to 0.43650, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.05-0.44.h5\n",
      "5536/5536 [==============================] - 688s 124ms/step - loss: 0.4178 - accuracy: 0.8250 - val_loss: 0.4365 - val_accuracy: 0.8142\n",
      "Epoch 6/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.8314\n",
      "Epoch 00006: val_loss improved from 0.43650 to 0.43026, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.06-0.43.h5\n",
      "5536/5536 [==============================] - 691s 125ms/step - loss: 0.4081 - accuracy: 0.8314 - val_loss: 0.4303 - val_accuracy: 0.8185\n",
      "Epoch 7/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.8369\n",
      "Epoch 00007: val_loss improved from 0.43026 to 0.42801, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.07-0.43.h5\n",
      "5536/5536 [==============================] - 682s 123ms/step - loss: 0.4001 - accuracy: 0.8369 - val_loss: 0.4280 - val_accuracy: 0.8194\n",
      "Epoch 8/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.8414\n",
      "Epoch 00008: val_loss improved from 0.42801 to 0.42449, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.08-0.42.h5\n",
      "5536/5536 [==============================] - 701s 127ms/step - loss: 0.3935 - accuracy: 0.8414 - val_loss: 0.4245 - val_accuracy: 0.8232\n",
      "Epoch 9/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8441\n",
      "Epoch 00009: val_loss improved from 0.42449 to 0.42361, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.09-0.42.h5\n",
      "5536/5536 [==============================] - 692s 125ms/step - loss: 0.3895 - accuracy: 0.8441 - val_loss: 0.4236 - val_accuracy: 0.8233\n",
      "Epoch 10/25\n",
      "5536/5536 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8488\n",
      "Epoch 00010: val_loss improved from 0.42361 to 0.42243, saving model to /content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.10-0.42.h5\n",
      "5536/5536 [==============================] - 688s 124ms/step - loss: 0.3824 - accuracy: 0.8488 - val_loss: 0.4224 - val_accuracy: 0.8242\n",
      "Epoch 11/25\n",
      "2554/5536 [============>.................] - ETA: 5:49 - loss: 0.3745 - accuracy: 0.8540Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "trained_model = model.fit(x=[q1_train_final, q2_train_final], y=y_train_final,\n",
    "                          validation_data=([q1_valid_final, q2_valid_final], y_valid_final), \n",
    "                          batch_size=batch_size, epochs=n_epochs, \n",
    "                          callbacks=my_callbacks\n",
    "                          )\n",
    "end = time.time()\n",
    "print(f\"Time taken to train {n_epochs} epochs is {datetime.timedelta(seconds=int(end-start))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMzXp3zM2F17"
   },
   "outputs": [],
   "source": [
    "# model.save('/content/drive/My Drive/Text Mining Project/Saved Model/myModel.h5', overwrite=True, include_optimizer=True)\n",
    "# model.save_weights('/content/drive/My Drive/Text Mining Project/Saved Model/myModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "LdzfkdpI2F17"
   },
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('/content/drive/My Drive/Text Mining Project/Saved Model/myModel.h5')\n",
    "model.load_weights(\"/content/drive/My Drive/Text Mining Project/Saved Model/Callbacks/model.12-0.41.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "-QH5dzCX2F18"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([q1_test_padded, q2_test_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "b7VpIeDz2F2B"
   },
   "outputs": [],
   "source": [
    "def prob_to_classes(y_pred, threshold=0.5):\n",
    "  global y_test\n",
    "  predicted_classes = np.empty_like(y_test)\n",
    "  for i in range(len(y_pred)):\n",
    "    if y_pred[i][0] >= threshold:\n",
    "      predicted_classes[i] = 1\n",
    "    else:\n",
    "      predicted_classes[i] = 0\n",
    "  return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "GONUxZjH3clf"
   },
   "outputs": [],
   "source": [
    "predicted_classes = prob_to_classes(y_pred, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-rWORIfZ10w",
    "outputId": "314c1017-e75d-43f6-9c6c-33a05dc999d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8252\n"
     ]
    }
   ],
   "source": [
    "acc = np.sum(predicted_classes == y_test)/len(y_test)\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJb7vakC2F2C",
    "outputId": "aa302038-725e-4a5f-ea6c-66f66a1656c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      6308\n",
      "           1       0.76      0.77      0.76      3692\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Siamese_Just_Sigmoid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
